<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Arnaud | Assistant RAG Interactif (3D)</title>
  
  <!-- Tailwind CSS -->
  <script src="https://cdn.tailwindcss.com"></script>
  <!-- Poppins Font -->
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600;700;800;900&display=swap" rel="stylesheet" />

  <style>
    /* Assure la hauteur complète pour un centrage correct */
    html, body {
      height: 100%;
    }    /* === GLOBAL === */
    body {
      font-family: 'Poppins', sans-serif;
      margin: 0;
      min-height: 100vh;
      overflow-x: hidden;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      
      /* FIX: Forcer le fond sombre avec !important pour contrer l'override de l'environnement */
      background: radial-gradient(circle at top center, #0d1117 0%, #000000 100%) !important;
      color: #fff !important; /* Forcer le texte en blanc */
      
      padding: 2rem;
      animation: fadeIn 0.8s ease-in-out;
    }

    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(20px); }
      to { opacity: 1; transform: translateY(0); }
    }

    /* === STRUCTURE === */
    #main-app-container {
      width: 100%;
      max-width: 900px;
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 2.5rem;
    }

    #spline-wrapper {
      width: 100%;
      max-width: 400px;
      height: 250px;
      position: relative;
    }

    #canvas3d {
      width: 100%;
      height: 100%;
      border-radius: 1rem;
    }

    /* === TEXT ZONE === */
    #response-display {
      min-height: 100px;
      text-align: center;
      font-size: 2.25rem;
      line-height: 1.3;
      font-weight: 800;
      color: #fff;
      padding: 0 1rem;
      width: 100%;
      background-color: transparent;
      border: none;
      opacity: 1;
      transition: opacity 0.5s ease-in-out;
    }

    /* === INPUT BAR === */
    #input-bar {
      width: 100%;
      max-width: 650px;
      margin-top: 2rem;
    }

    #user-input {
      border: 2px solid rgba(255, 255, 255, 0.4);
      /* Forcer les couleurs pour le thème sombre */
      background-color: rgba(255, 255, 255, 0.05) !important;
      color: #fff !important; /* Forcer le texte de l'input en blanc */
      padding: 1rem 1.5rem;
      border-radius: 9999px;
      transition: all 0.2s;
      box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
    }

    #user-input::placeholder {
      color: rgba(255, 255, 255, 0.6) !important; /* Forcer la couleur du placeholder */
    }

    #user-input:focus {
      border-color: #3b82f6;
      outline: none;
    }

    #send-button {
      background-color: transparent !important;
      border: 2px solid #3b82f6 !important;
      color: #3b82f6 !important;
      padding: 1rem 2rem;
      border-radius: 9999px;
      font-weight: 700;
      transition: all 0.2s;
      box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
    }

    #send-button:hover {
      background-color: rgba(59, 130, 246, 0.1) !important;
    }

    #send-button:active {
      transform: scale(0.95);
    }

    /* === LOADING DOTS === */
    .loading-dot {
      animation: bounce 0.6s infinite alternate;
      display: inline-block;
      width: 8px;
      height: 8px;
      background-color: #3b82f6;
      border-radius: 50%;
      margin: 0 4px;
    }

    .loading-dot:nth-child(2) { animation-delay: 0.2s; }
    .loading-dot:nth-child(3) { animation-delay: 0.4s; }

    @keyframes bounce {
      to {
        transform: translateY(-5px);
      }
    }    /* === VOICE WAVE === */
    #voice-wave {
      width: 100px;
      height: 6px;
      border-radius: 3px;
      background: linear-gradient(90deg, #3b82f6, #60a5fa);
      animation: pulse 0.8s infinite alternate;
      margin-top: 1rem;
    }

    @keyframes pulse {
      from {
        opacity: 0.3;
        transform: scaleX(0.8);
      }
      to {
        opacity: 1;
        transform: scaleX(1.1);
      }
    }    @media (max-width: 768px) {
      #response-display { font-size: 1.5rem; }
      #spline-wrapper { height: 200px; max-width: 300px; }
      #user-input, #send-button { padding: 0.75rem 1rem; }
    }
  </style>
</head>
<body>
  <div id="main-app-container">
    <!-- SPLINE -->
    <div id="spline-wrapper" class="flex justify-center items-center">
      <canvas id="canvas3d"></canvas>
    </div>

    <!-- RÉPONSE -->
    <div id="response-display" aria-live="polite">
      Bonjour, je suis Arnaud. Que puis-je faire pour vous aujourd'hui ?
    </div>
    <div id="voice-wave" class="hidden"></div>

    <!-- INPUT -->
    <div id="input-bar">
      <div class="flex items-center space-x-3">
        <input type="text" id="user-input" placeholder="Votre question d'entretien..."
          class="flex-grow"
          onkeydown="if(event.key === 'Enter') sendMessage()">
        <button id="send-button" onclick="sendMessage()">Envoyer</button>
      </div>
    </div>
  </div>

  <!-- SCRIPT -->
  <script type="module">
    import { Application } from "https://unpkg.com/@splinetool/runtime@1.6.3/build/runtime.js";

    const userInput = document.getElementById('user-input');
    const sendButton = document.getElementById('send-button');
    const responseDisplay = document.getElementById('response-display');
    const voiceWave = document.getElementById('voice-wave');
    const canvas3d = document.getElementById('canvas3d');

    let splineApp, currentAudio = null;

    // === Initialisation Spline ===
    const observer = new IntersectionObserver(entries => {
      if (entries[0].isIntersecting) {
        splineApp = new Application(canvas3d);
        // Spline scene URL provided by the user
        splineApp.load('https://prod.spline.design/Jpxk6lxmkWLWUPls/scene.splinecode')
          .then(() => console.log("Scène Spline 3D chargée."));
        observer.disconnect();
      }
    });
    observer.observe(document.getElementById('spline-wrapper'));

    // === UTILITAIRES ===

    /** Converts a Base64 string to an ArrayBuffer. */
    function base64ToArrayBuffer(base64) {
      const binaryString = atob(base64);
      const len = binaryString.length;
      const bytes = new Uint8Array(len);
      for (let i = 0; i < len; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }
      return bytes.buffer;
    }

    /** Writes a string to a DataView at a specific offset. */
    function writeString(view, offset, string) {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    }

    /** Converts 16-bit PCM ArrayBuffer to a WAV Blob. */
    function pcmToWav(pcm16, sampleRate) {
      const numChannels = 1;
      const bytesPerSample = 2; // Int16Array (16-bit PCM)
      const blockAlign = numChannels * bytesPerSample;
      const byteRate = sampleRate * blockAlign;
      const dataSize = pcm16.length * bytesPerSample;
      const buffer = new ArrayBuffer(44 + dataSize);
      const view = new DataView(buffer);

      // RIFF chunk
      writeString(view, 0, 'RIFF');
      view.setUint32(4, 36 + dataSize, true); // File size
      writeString(view, 8, 'WAVE');

      // fmt sub-chunk
      writeString(view, 12, 'fmt ');
      view.setUint32(16, 16, true); // Sub-chunk size (16 for PCM)
      view.setUint16(20, 1, true); // Audio format (1 for PCM)
      view.setUint16(22, numChannels, true);
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, byteRate, true);
      view.setUint16(32, blockAlign, true);
      view.setUint16(34, 16, true); // Bits per sample (16-bit)

      // data sub-chunk
      writeString(view, 36, 'data');
      view.setUint32(40, dataSize, true);

      // Write PCM data
      let offset = 44;
      for (let i = 0; i < pcm16.length; i++, offset += 2) {
        view.setInt16(offset, pcm16[i], true);
      }

      return new Blob([buffer], { type: 'audio/wav' });
    }

    function showLoading() {
      responseDisplay.style.opacity = 0;
      responseDisplay.innerHTML = `
        <div class="flex justify-center items-center space-x-2 w-full h-full">
          <span class="loading-dot"></span>
          <span class="loading-dot"></span>
          <span class="loading-dot"></span>
        </div>`;
      responseDisplay.style.opacity = 1;
    }

    function typeWriterEffect(text) {
      let i = 0;
      responseDisplay.innerHTML = '';
      responseDisplay.style.textAlign = 'center';
      return new Promise(resolve => {
        const speed = 40;
        const interval = setInterval(() => {
          responseDisplay.innerHTML = text.slice(0, ++i);
          if (i >= text.length) {
            clearInterval(interval);
            resolve();
          }
        }, speed);
      });
    }

    function handleError(error, userMessage = "Une erreur est survenue. Veuillez réessayer.") {
      console.error(error);
      responseDisplay.innerHTML = userMessage;
      responseDisplay.style.opacity = 1;
    }

    // === TTS PREPARATION ===
    async function prepareAudio(text) {
      // The API key is automatically provided by the Canvas environment when set to ""
      const apiKey = ""; 
      const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`;
      const payload = {
        contents: [{ parts: [{ text }] }],
        generationConfig: {
          responseModalities: ["AUDIO"],
          speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: "Kore" } } }
        },
        model: "gemini-2.5-flash-preview-tts"
      };

      if (currentAudio) {
        currentAudio.pause();
        currentAudio = null;
      }
      
      // Exponential Backoff for API call robustness
      const maxRetries = 3;
      for (let attempt = 0; attempt < maxRetries; attempt++) {
        try {
          // 1. Appel API pour la synthèse vocale (attendre les données)
          const response = await fetch(apiUrl, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(payload)
          });
          
          if (!response.ok) {
                if (response.status === 429 || response.status >= 500) {
                    if (attempt < maxRetries - 1) {
                        const delay = Math.pow(2, attempt) * 1000 + Math.random() * 500;
                        await new Promise(resolve => setTimeout(resolve, delay));
                        continue; // Retry
                    }
                }
                throw new Error(`Erreur API TTS (${response.status})`);
            }
          
          const result = await response.json();
          const part = result?.candidates?.[0]?.content?.parts?.[0];
          const audioData = part?.inlineData?.data;
          const mimeType = part?.inlineData?.mimeType;

          if (!audioData || !mimeType) throw new Error("Réponse TTS invalide (données audio ou MIME type manquants).");
          
          // 2. Conversion PCM en WAV (synchrone)
          const sampleRateMatch = mimeType.match(/rate=(\d+)/);
          if (!sampleRateMatch || sampleRateMatch.length < 2) throw new Error("Sample rate missing from MIME type.");
          
          const sampleRate = parseInt(sampleRateMatch[1], 10);
          const pcmData = base64ToArrayBuffer(audioData);
          const pcm16 = new Int16Array(pcmData);
          
          const wavBlob = pcmToWav(pcm16, sampleRate);
          const audioUrl = URL.createObjectURL(wavBlob);
          
          // 3. Retourner l'objet Audio prêt à jouer et son URL pour révocation
          const newAudio = new Audio(audioUrl);
          return { audio: newAudio, url: audioUrl };
        } catch (err) {
          if (attempt === maxRetries - 1) {
            throw err; // Rejeter la dernière erreur
          }
        }
      }
    }

    // === BACKEND (simulé) ===
    function simulateBackendResponse(query) {
      return new Promise(resolve => {
        setTimeout(() => {
          let response = `(Réponse simulée de l'IA) Pour répondre à "${query}", Arnaud a déjà traité ce cas.`;
          if (query.toLowerCase().includes('échec')) {
            response = "Selon le CV, son échec majeur fut de croire au planning initial du projet de migration. Il a appris l'importance d'une gestion des risques proactive.";
          } else if (query.toLowerCase().includes('sap')) {
            response = "Arnaud maîtrise SAP FI/CO et a simplifié l'expérience utilisateur de Fiori pour les financiers, améliorant l'adoption de 30%.";
          } else if (query.toLowerCase().includes('rag') || query.toLowerCase().includes('ia')) {
            response = "L'IA ? C’est le RAG en action : Arnaud l’a conçu avec souveraineté et précision, intégrant des mécanismes d'audit pour garantir la fiabilité des données.";
          } else if (query.toLowerCase().includes('bonjour')) {
                response = "Bonjour ! Je suis l'assistant interactif d'Arnaud. Posez-moi des questions sur son parcours professionnel ou ses compétences.";
            } else if (query.toLowerCase().includes('merci')) {
                response = "De rien ! N'hésitez pas si vous avez d'autres questions sur mes expériences.";
            } else {
                response = `Intéressante question. Analysons les archives d'Arnaud pour répondre à : "${query}".`;
            }
          resolve(response);
        }, 1500 + Math.random() * 1000);
      });
    }

    // === MAIN ===
    async function sendMessage() {
      const query = userInput.value.trim();
      if (!query) return;
      sendButton.disabled = true;
      userInput.disabled = true;
      showLoading();
      userInput.value = '';
      
      let responseText = '';
      let audioUrlToRevoke = null;

      try {
        // 1. Obtenir la réponse backend (étape de stockage du texte)
        responseText = await simulateBackendResponse(query);
        
        // 2. Démarrer la préparation de l'audio (TTS network call)
        const audioPrepPromise = prepareAudio(responseText);
        
        // 3. ATTENDRE que l'objet Audio soit prêt pour garantir le démarrage simultané.
        let audio = null;
        try {
          const result = await audioPrepPromise;
          audio = result.audio;
          audioUrlToRevoke = result.url;
          currentAudio = audio;
        } catch (ttsError) {
          console.error("Échec de la préparation TTS, affichage du texte seul.", ttsError);
        }

        // 4. Démarrage SIMULTANÉ du typing et de l'audio (si disponible)
        const typingPromise = typeWriterEffect(responseText);
        let audioPlayPromise = Promise.resolve();

        if (audio) {
          audioPlayPromise = new Promise(resolve => {
            voiceWave.classList.remove('hidden');

            audio.onended = () => {
              voiceWave.classList.add('hidden');
              resolve();
            };
            
            // Lecture audio immédiate.
            audio.play().catch(e => {
              console.error("Échec de la lecture audio, résolution immédiate:", e);
              voiceWave.classList.add('hidden');
              resolve();
            });
          });
        }
        
        // 5. Attendre que le typing et la lecture audio soient terminés
        await Promise.all([typingPromise, audioPlayPromise]);

        if (splineApp) console.log("Interaction Spline possible :", query);
      } catch (err) {
        handleError(err, "Une erreur s'est produite lors de la récupération de la réponse.");
      } finally {
          // 6. Nettoyage de l'URL Blob
          if (audioUrlToRevoke) {
              URL.revokeObjectURL(audioUrlToRevoke);
          }
        sendButton.disabled = false;
        userInput.disabled = false;
        userInput.focus();
      }
    }
    
    // Expose sendMessage to the global scope for the HTML onclick/onkeydown attributes
    window.sendMessage = sendMessage;
    
    window.onload = () => userInput.focus();
  </script>
</body>
</html>